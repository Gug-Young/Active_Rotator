{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def tf_check_type(t, y0): # Ensure Input is Correct\n",
    "    if not (y0.dtype.is_floating and t.dtype.is_floating):\n",
    "        raise TypeError('Error in Datatype')\n",
    "\n",
    "class _Tf_Integrator():\n",
    "    \n",
    "    def __init__(self,n_,F_b): \n",
    "        # class constructor to get inputs for number of neurons and firing thresholds\n",
    "        self.n_ = n_\n",
    "        self.F_b = F_b\n",
    "    \n",
    "    def integrate(self, func, y0, t): \n",
    "        time_delta_grid = t[1:] - t[:-1]\n",
    "        \n",
    "        def scan_func(y, t_dt): \n",
    "            # recall the necessary variables\n",
    "            n_ = self.n_\n",
    "            F_b = self.F_b\n",
    "            \n",
    "            t, dt = t_dt\n",
    "            \n",
    "            # Differential updation\n",
    "            dy = self._step_func(func,t,dt,y) # Make code more modular.\n",
    "            dy = tf.cast(dy, dtype=y.dtype) # Failsafe\n",
    "           \n",
    "            out = y + dy # the result after differential updation\n",
    "        \n",
    "            # Conditional to use specialized Integrator vs Normal Integrator (n=0)\n",
    "            if n_>0:\n",
    "                \n",
    "                # Extract the last n variables for fire times\n",
    "                fire_t = y[-n_:] \n",
    "                \n",
    "                # Value of change in firing times if neuron didnt fire = 0\n",
    "                l = tf.zeros(tf.shape(fire_t),dtype=fire_t.dtype) \n",
    "                \n",
    "                # Value of change in firing times if neuron fired = Current Time - Last Fire Time\n",
    "                l_ = t-fire_t \n",
    "                \n",
    "                # Check if Voltage is initially less than Firing Threshold\n",
    "                z = tf.less(y[:n_],F_b)              \n",
    "                # Check if Voltage is more than Firing Threshold after updation\n",
    "                z_ = tf.greater_equal(out[:n_],F_b)  \n",
    "                \n",
    "                # tf.where(cond,a,b) chooses elements from a/b based on condition \n",
    "                df = tf.where(tf.logical_and(z,z_),l_,l) \n",
    "                \n",
    "                fire_t_ = fire_t+df # Update firing time \n",
    "                \n",
    "                return tf.concat([out[:-n_],fire_t_],0)\n",
    "            else:\n",
    "                return out\n",
    "            \n",
    "        y = tf.scan(scan_func, (t[:-1], time_delta_grid),y0)\n",
    "        \n",
    "        return tf.concat([[y0], y], axis=0)\n",
    "    \n",
    "    def _step_func(self, func, t, dt, y):\n",
    "        k1 = func(y, t)\n",
    "        half_step = t + dt / 2\n",
    "        dt_cast = tf.cast(dt, y.dtype) # Failsafe\n",
    "\n",
    "        k2 = func(y + dt_cast * k1 / 2, half_step)\n",
    "        k3 = func(y + dt_cast * k2 / 2, half_step)\n",
    "        k4 = func(y + dt_cast * k3, t + dt)\n",
    "        return tf.add_n([k1, 2 * k2, 2 * k3, k4]) * (dt_cast / 6)\n",
    "    \n",
    "\n",
    "def odeint(func, y0, t, n_, F_b):\n",
    "    t = tf.convert_to_tensor(t, preferred_dtype=tf.float64, name='t')\n",
    "    y0 = tf.convert_to_tensor(y0, name='y0')\n",
    "    tf_check_type(y0,t)\n",
    "    return _Tf_Integrator(n_, F_b).integrate(func,y0,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'device' is an invalid keyword argument for print()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 'NVIDIA TITAN X (Pascal)'\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 사용 가능 GPU 개수 체크\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()) \u001b[38;5;66;03m# 3\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'device' is an invalid keyword argument for print()"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(), device = 0) # 'NVIDIA TITAN X (Pascal)'\n",
    "\n",
    "# 사용 가능 GPU 개수 체크\n",
    "print(torch.cuda.device_count()) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536 ms ± 22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A = torch.rand(10000,10000); A*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910 ms ± 11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A =np.random.uniform(0,10,(10000,10000)); A*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11031011849094813291\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930 ms ± 9.93 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A =np.random.uniform(0,10,(10000,10000)); A*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpus:\n",
    "  # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 10000), dtype=float64, numpy=\n",
       "array([[6.78639361, 8.84822572, 6.75862781, ..., 8.07710184, 7.55234465,\n",
       "        1.05932184],\n",
       "       [7.69569792, 1.04387733, 0.30263859, ..., 0.28012655, 8.19744003,\n",
       "        6.79672891],\n",
       "       [3.98872136, 5.99812428, 8.87878871, ..., 7.39085097, 5.69538107,\n",
       "        3.2847324 ],\n",
       "       ...,\n",
       "       [3.54046004, 4.75156258, 8.61203232, ..., 2.13428668, 6.44659815,\n",
       "        6.53302763],\n",
       "       [9.3342556 , 7.50258148, 4.76895438, ..., 6.5982546 , 0.75164193,\n",
       "        9.83735197],\n",
       "       [3.32612691, 0.2091439 , 7.84296322, ..., 2.5566032 , 2.66618231,\n",
       "        9.21706286]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform((10000,10000),0.,10.,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A = np.ran((10000,10000),0.,10.,dtype=np.float64); A*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "573 ms ± 15.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A = tf.random.uniform((10000,10000),0.,10.,dtype=np.float64); A*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.random.uniform((1000,1000),0.,10.,dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =np.random.uniform(0,10,(1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "@jit(nopython = True)\n",
    "def RKHG(f,y0,t,D,args=()):\n",
    "    n = len(t)\n",
    "    size = len(y0)\n",
    "    y = np.zeros((n, size))\n",
    "    y[0] = y0\n",
    "    h = t[1] - t[0]\n",
    "    sh = np.sqrt(h)\n",
    "    for i in range(n - 1):\n",
    "        S = np.random.choice(np.array([-1,1]),size=size)\n",
    "        dW = np.random.normal(0,1,size)*sh\n",
    "        k1 = h*f(y[i],t[i],*args) + (dW - S*sh)*D\n",
    "        k2 = h*f(y[i]+k1,t[i]+h,*args) + (dW + S*sh)*D\n",
    "        y[i+1] = y[i] + 0.5*(k1+k2)\n",
    "    return y\n",
    "\n",
    "\n",
    "def RK4(f, y0, t, args=()):\n",
    "    n = len(t)\n",
    "    y = np.zeros((n, len(y0)))\n",
    "    y[0] = y0\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        h = t[i + 1] - t[i]\n",
    "        k1 = f(y[i], t[i], *args)\n",
    "        k2 = f(y[i] + k1 * h / 2.0, t[i] + h / 2.0, *args)\n",
    "        k3 = f(y[i] + k2 * h / 2.0, t[i] + h / 2.0, *args)\n",
    "        k4 = f(y[i] + k3 * h, t[i] + h, *args)\n",
    "        y[i + 1] = y[i] + (h / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    return y\n",
    "from scipy.special import erfinv\n",
    "import scipy.stats as scs\n",
    "\n",
    "def _make_init_theta_(seed,N):\n",
    "    if type(seed)==str:\n",
    "        init_theta= np.linspace(-np.pi,np.pi,N,endpoint=False)\n",
    "    else:\n",
    "        np.random.seed(seed)\n",
    "        init_theta = np.random.uniform(-np.pi, np.pi, size=N)\n",
    "    return init_theta\n",
    "def Q_Normal(N, mean=0, sigma=1,seed=None):\n",
    "    \"\"\"return theta, omega, Kc\"\"\"\n",
    "    init_theta = _make_init_theta_(seed,N)\n",
    "    init_omega = np.array([mean +sigma*(2**0.5)*erfinv((2*i - N - 1)/(N+1)) for i in range(1,N+1)])\n",
    "    Kc = 2 / (np.pi * scs.cauchy.pdf(mean, mean, sigma))\n",
    "    return init_theta, init_omega, Kc\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def get_order_parameter(theta,N):\n",
    "    ''' get theta and return r and theta'''\n",
    "    rpsi = 1/N*np.sum(np.exp(1j*theta))\n",
    "    r = np.abs(rpsi)\n",
    "    psi = np.angle(rpsi)\n",
    "    return r,psi\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def Kuramoto_mf(Theta,t,omega,N,K):\n",
    "    # print(\"Case m = 0\")\n",
    "    Theta = Theta.copy()\n",
    "    theta = Theta[:N]\n",
    "    r,psi = get_order_parameter(theta,N)\n",
    "    dtheta = omega + K*r*np.sin(psi - theta)\n",
    "    Theta[:N] = dtheta\n",
    "    return Theta\n",
    "\n",
    "\n",
    "def Kuramoto(Theta,t,omega,N,K):\n",
    "    # print(\"Case m = 0\")\n",
    "    Theta = Theta.copy()\n",
    "    theta = Theta[:N]\n",
    "    theta_i,theta_j = np.meshgrid(theta,theta,sparse=True)\n",
    "    dtheta = omega + K/N*np.sum(np.sin(theta_j - theta_i),axis=0)\n",
    "    Theta[:N] = dtheta\n",
    "    return Theta\n",
    "\n",
    "@jit(nopython=True)\n",
    "def Kuramoto_mf_AR(Theta,t,omega,N,K,b):\n",
    "    # print(\"Case m = 0\")\n",
    "    Theta = Theta.copy()\n",
    "    theta = Theta[:N]\n",
    "    r,psi = get_order_parameter(theta,N)\n",
    "    dtheta = omega + K*r*np.sin(psi - theta) - b*np.sin(theta)\n",
    "    Theta[:N] = dtheta\n",
    "    return Theta\n",
    "\n",
    "\n",
    "def Kuramoto_AR(Theta,t,omega,N,K,b):\n",
    "    # print(\"Case m = 0\")\n",
    "    Theta = Theta.copy()\n",
    "    theta = Theta[:N]\n",
    "    theta_i,theta_j = np.meshgrid(theta,theta,sparse=True)\n",
    "    dtheta = omega + K/N*np.sum(np.sin(theta_j - theta_i),axis=0) - b*np.sin(theta)\n",
    "    Theta[:N] = dtheta\n",
    "    return Theta\n",
    "\n",
    "\n",
    "N = 1000\n",
    "\n",
    "theta_random, omega, Kc = Q_Normal(N, 0, 1, seed=10)\n",
    "omega = np.sort(omega)-np.mean(omega)\n",
    "omega = np.ones(N)\n",
    "K = 1\n",
    "t_end = 200\n",
    "dt = 0.1\n",
    "t = np.arange(0, t_end+dt/2, dt)\n",
    "# D = 0.5\n",
    "b = 1.10\n",
    "Ds =np.linspace(0.0,1.0,50)\n",
    "chis = []\n",
    "d_rsigma = []\n",
    "dtheta_s = []\n",
    "for D in tqdm(Ds):\n",
    "    # sol = RKHG(Kuramoto_mf,theta_random,t,D, args=(omega, N, K))\n",
    "    # sol = RKHG(Kuramoto_mf,theta_random,t,D, args=(omega, N, K))\n",
    "    sol = RKHG(Kuramoto_mf_AR,theta_random,t,D, args=(omega, N, K,b))\n",
    "    # sol = RKHG(Kuramoto_AR,theta_random,t,D, args=(omega, N, K,b))\n",
    "    th = 0\n",
    "    theta_s = sol[th:,:N]\n",
    "    rabs = np.mean(np.exp(theta_s.T*1j),axis=0)\n",
    "    # rabs = rabs_[len(t)//2:]\n",
    "    r = np.abs(rabs)\n",
    "    r_mean = np.mean(r[-len(r)//2:])\n",
    "    sigma_phi = np.mean(rabs[-len(r)//2:])\n",
    "    sigma = np.abs(sigma_phi)\n",
    "    psi = np.abs(sigma_phi)\n",
    "    chi = np.mean(np.abs(rabs-sigma_phi)**2)*N\n",
    "    chis.append(chi)\n",
    "    d_rsigma.append(np.abs(r_mean-sigma))\n",
    "    dtheta = (sol[-1] - sol[0])/(t[-1]-t[0])\n",
    "    dtheta = np.sort(dtheta)\n",
    "    dtheta_s.append(dtheta)\n",
    "    plt.plot(dtheta)\n",
    "\n",
    "np.mean(dtheta_s,axis=1)\n",
    "plt.plot(Ds, np.mean(dtheta_s,axis=1))\n",
    "\n",
    "\n",
    "# plt.twinx()\n",
    "plt.twinx()\n",
    "plt.plot(Ds,chis,color='red')\n",
    "# plt.twinx()\n",
    "plt.plot(Ds,d_rsigma)\n",
    "plt.axvline(D)\n",
    "MAX_D = Ds[np.argmax(chis)]\n",
    "MAX_D,np.max(chis),b\n",
    "(t.reshape(-1,1)*np.ones_like(sol)).shape\n",
    "sol.shape\n",
    "for i in range(10):\n",
    "    plt.plot(sol.T[i]-sol.T[i][0])\n",
    "plt.yticks(np.pi*np.arange(0,22,2),[r'$%d\\pi$'%pi for pi in np.arange(0,22,2)])\n",
    "plt.grid()\n",
    "ro_count = sol[:]//(np.pi*2)\n",
    "arg_sort = np.argsort(ro_count[-1])\n",
    "mean_count = np.mean(ro_count,axis=1)\n",
    "std_count  = np.std(ro_count,axis=1)\n",
    "plt.plot(t,mean_count)\n",
    "plt.fill_between(t,mean_count-std_count,mean_count+std_count,alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2540175027.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python cnf.py --viz\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python cnf.py --viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--adjoint] [nbounces]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/kimgug-young/Library/Jupyter/runtime/kernel-v2-735gFjfN02BkzAz.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "from torchdiffeq import odeint_event\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "class BouncingBallExample(nn.Module):\n",
    "    def __init__(self, radius=0.2, gravity=9.8, adjoint=False):\n",
    "        super().__init__()\n",
    "        self.gravity = nn.Parameter(torch.as_tensor([gravity]))\n",
    "        self.log_radius = nn.Parameter(torch.log(torch.as_tensor([radius])))\n",
    "        self.t0 = nn.Parameter(torch.tensor([0.0]))\n",
    "        self.init_pos = nn.Parameter(torch.tensor([10.0]))\n",
    "        self.init_vel = nn.Parameter(torch.tensor([0.0]))\n",
    "        self.absorption = nn.Parameter(torch.tensor([0.2]))\n",
    "        self.odeint = odeint_adjoint if adjoint else odeint\n",
    "\n",
    "    def forward(self, t, state):\n",
    "        pos, vel, log_radius = state\n",
    "        dpos = vel\n",
    "        dvel = -self.gravity\n",
    "        return dpos, dvel, torch.zeros_like(log_radius)\n",
    "\n",
    "    def event_fn(self, t, state):\n",
    "        # positive if ball in mid-air, negative if ball within ground.\n",
    "        pos, _, log_radius = state\n",
    "        return pos - torch.exp(log_radius)\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        state = (self.init_pos, self.init_vel, self.log_radius)\n",
    "        return self.t0, state\n",
    "\n",
    "    def state_update(self, state):\n",
    "        \"\"\"Updates state based on an event (collision).\"\"\"\n",
    "        pos, vel, log_radius = state\n",
    "        pos = (\n",
    "            pos + 1e-7\n",
    "        )  # need to add a small eps so as not to trigger the event function immediately.\n",
    "        vel = -vel * (1 - self.absorption)\n",
    "        return (pos, vel, log_radius)\n",
    "\n",
    "    def get_collision_times(self, nbounces=1):\n",
    "\n",
    "        event_times = []\n",
    "\n",
    "        t0, state = self.get_initial_state()\n",
    "\n",
    "        for i in range(nbounces):\n",
    "            event_t, solution = odeint_event(\n",
    "                self,\n",
    "                state,\n",
    "                t0,\n",
    "                event_fn=self.event_fn,\n",
    "                reverse_time=False,\n",
    "                atol=1e-8,\n",
    "                rtol=1e-8,\n",
    "                odeint_interface=self.odeint,\n",
    "            )\n",
    "            event_times.append(event_t)\n",
    "\n",
    "            state = self.state_update(tuple(s[-1] for s in solution))\n",
    "            t0 = event_t\n",
    "\n",
    "        return event_times\n",
    "\n",
    "    def simulate(self, nbounces=1):\n",
    "        event_times = self.get_collision_times(nbounces)\n",
    "\n",
    "        # get dense path\n",
    "        t0, state = self.get_initial_state()\n",
    "        trajectory = [state[0][None]]\n",
    "        velocity = [state[1][None]]\n",
    "        times = [t0.reshape(-1)]\n",
    "        for event_t in event_times:\n",
    "            tt = torch.linspace(\n",
    "                float(t0), float(event_t), int((float(event_t) - float(t0)) * 50)\n",
    "            )[1:-1]\n",
    "            tt = torch.cat([t0.reshape(-1), tt, event_t.reshape(-1)])\n",
    "            solution = odeint(self, state, tt, atol=1e-8, rtol=1e-8)\n",
    "\n",
    "            trajectory.append(solution[0][1:])\n",
    "            velocity.append(solution[1][1:])\n",
    "            times.append(tt[1:])\n",
    "\n",
    "            state = self.state_update(tuple(s[-1] for s in solution))\n",
    "            t0 = event_t\n",
    "\n",
    "        return (\n",
    "            torch.cat(times),\n",
    "            torch.cat(trajectory, dim=0).reshape(-1),\n",
    "            torch.cat(velocity, dim=0).reshape(-1),\n",
    "            event_times,\n",
    "        )\n",
    "\n",
    "\n",
    "def gradcheck(nbounces):\n",
    "\n",
    "    system = BouncingBallExample()\n",
    "\n",
    "    variables = {\n",
    "        \"init_pos\": system.init_pos,\n",
    "        \"init_vel\": system.init_vel,\n",
    "        \"t0\": system.t0,\n",
    "        \"gravity\": system.gravity,\n",
    "        \"log_radius\": system.log_radius,\n",
    "    }\n",
    "\n",
    "    event_t = system.get_collision_times(nbounces)[-1]\n",
    "    event_t.backward()\n",
    "\n",
    "    analytical_grads = {}\n",
    "    for name, p in system.named_parameters():\n",
    "        for var in variables.keys():\n",
    "            if var in name:\n",
    "                analytical_grads[var] = p.grad\n",
    "\n",
    "    eps = 1e-3\n",
    "\n",
    "    fd_grads = {}\n",
    "\n",
    "    for var, param in variables.items():\n",
    "        orig = param.data\n",
    "        param.data = orig - eps\n",
    "        f_meps = system.get_collision_times(nbounces)[-1]\n",
    "        param.data = orig + eps\n",
    "        f_peps = system.get_collision_times(nbounces)[-1]\n",
    "        param.data = orig\n",
    "        fd = (f_peps - f_meps) / (2 * eps)\n",
    "        fd_grads[var] = fd\n",
    "\n",
    "    success = True\n",
    "    for var in variables.keys():\n",
    "        analytical = analytical_grads[var]\n",
    "        fd = fd_grads[var]\n",
    "        if torch.norm(analytical - fd) > 1e-4:\n",
    "            success = False\n",
    "            print(\n",
    "                f\"Got analytical grad {analytical.item()} for {var} param but finite difference is {fd.item()}\"\n",
    "            )\n",
    "\n",
    "    if not success:\n",
    "        raise Exception(\"Gradient check failed.\")\n",
    "\n",
    "    print(\"Gradient check passed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Process some integers.\")\n",
    "    parser.add_argument(\"nbounces\", type=int, nargs=\"?\", default=10)\n",
    "    parser.add_argument(\"--adjoint\", action=\"store_true\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    gradcheck(args.nbounces)\n",
    "\n",
    "    system = BouncingBallExample()\n",
    "    times, trajectory, velocity, event_times = system.simulate(nbounces=args.nbounces)\n",
    "    times = times.detach().cpu().numpy()\n",
    "    trajectory = trajectory.detach().cpu().numpy()\n",
    "    velocity = velocity.detach().cpu().numpy()\n",
    "    event_times = torch.stack(event_times).detach().cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(7, 3.5))\n",
    "\n",
    "    # Event locations.\n",
    "    for event_t in event_times:\n",
    "        plt.plot(\n",
    "            event_t,\n",
    "            0.0,\n",
    "            color=\"C0\",\n",
    "            marker=\"o\",\n",
    "            markersize=7,\n",
    "            fillstyle=\"none\",\n",
    "            linestyle=\"\",\n",
    "        )\n",
    "\n",
    "    (vel,) = plt.plot(\n",
    "        times, velocity, color=\"C1\", alpha=0.7, linestyle=\"--\", linewidth=2.0\n",
    "    )\n",
    "    (pos,) = plt.plot(times, trajectory, color=\"C0\", linewidth=2.0)\n",
    "\n",
    "    plt.hlines(0, 0, 100)\n",
    "    plt.xlim([times[0], times[-1]])\n",
    "    plt.ylim([velocity.min() - 0.02, velocity.max() + 0.02])\n",
    "    plt.ylabel(\"Markov State\", fontsize=16)\n",
    "    plt.xlabel(\"Time\", fontsize=13)\n",
    "    plt.legend([pos, vel], [\"Position\", \"Velocity\"], fontsize=16)\n",
    "\n",
    "    plt.gca().xaxis.set_tick_params(\n",
    "        direction=\"in\", which=\"both\"\n",
    "    )  # The bottom will maintain the default of 'out'\n",
    "    plt.gca().yaxis.set_tick_params(\n",
    "        direction=\"in\", which=\"both\"\n",
    "    )  # The bottom will maintain the default of 'out'\n",
    "\n",
    "    # Hide the right and top spines\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    plt.gca().yaxis.set_ticks_position(\"left\")\n",
    "    plt.gca().xaxis.set_ticks_position(\"bottom\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"bouncing_ball.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
